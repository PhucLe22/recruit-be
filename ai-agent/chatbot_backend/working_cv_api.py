# Simple working CV API with real database integration
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime
import os
import time
import pickle
import re
from typing import List, Optional
from pymongo import MongoClient
from dotenv import load_dotenv
import random
from pydantic import BaseModel
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
import json

# Google Calendar Configuration
SCOPES = ['https://www.googleapis.com/auth/calendar']
CREDENTIALS_FILE = 'credentials.json'
TOKEN_FILE = 'token.pickle'

# Pydantic models
class GoogleMeetRequest(BaseModel):
    summary: str
    description: str
    start_time: str
    end_time: str
    timezone: str = "UTC"
    attendees: Optional[List[str]] = []

app = FastAPI(title="Working CV API with Real Database and Google Calendar")

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=['*'],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Load environment and connect to MongoDB
load_dotenv()
MONGO_ATLAS_URI = os.getenv("MONGO_ATLAS_URI")
DB_NAME = "CVProject"

# MongoDB connection
print("üîó Connecting to MongoDB...")
mongo_client = MongoClient(MONGO_ATLAS_URI)
db = mongo_client[DB_NAME]
jobs_collection = db["jobs"]
cvs_collection = db["cvs"]
users_collection = db["users"]

print("‚úÖ Connected to MongoDB successfully")

@app.get("/")
async def root():
    return {"status": "Working CV API with Real Database", "time": datetime.utcnow().isoformat()}

@app.get("/health")
async def health_check():
    try:
        # Test database connection
        db.command("ping")
        return {"status": "ok", "time": datetime.utcnow().isoformat(), "database": "connected"}
    except Exception as e:
        return {"status": "error", "time": datetime.utcnow().isoformat(), "database": "disconnected", "error": str(e)}

@app.get("/debug/jobs")
async def debug_jobs():
    """Debug endpoint to see current jobs count and sample"""
    try:
        total_jobs = jobs_collection.count_documents({})
        active_jobs = jobs_collection.count_documents({
            "status": {"$ne": "closed"},
            "expiryTime": {"$gt": datetime.utcnow()}
        })

        # Get a few sample jobs
        sample_jobs = list(jobs_collection.find({}, {"title": 1, "companyName": 1, "status": 1}).limit(3))
        job_samples = [{ "title": j.get("title", "No title"), "company": j.get("companyName", "No company"), "status": j.get("status", "unknown") } for j in sample_jobs]

        return {
            "total_jobs": total_jobs,
            "active_jobs": active_jobs,
            "sample_jobs": job_samples,
            "source": "mongodb"
        }
    except Exception as e:
        return {
            "total_jobs": 0,
            "active_jobs": 0,
            "sample_jobs": [],
            "error": str(e),
            "source": "error"
        }

@app.get("/api/jobs-suggestion/{username}")
async def jobs_suggestion(username: str):
    """Get job suggestions for a user with real database jobs"""
    try:
        # Check if user has CV uploaded (try to find in database)
        cv_doc = cvs_collection.find_one({"username": username})

        # If not found in database, try memory fallback
        if not cv_doc and hasattr(cvs_collection, 'find_one'):
            print(f"‚ö†Ô∏è No CV found for {username} in database")

        # Fetch real jobs from database
        jobs_cursor = jobs_collection.find({
            "status": {"$ne": "closed"},
            "expiryTime": {"$gt": datetime.utcnow()}
        })

        # Convert cursor to list and format
        real_jobs = []
        for job in jobs_cursor.limit(10):  # Limit to 10 most relevant jobs
            match_percentage = random.randint(60, 95)  # Mock matching percentage for demo
            status_emoji = "üü¢" if match_percentage >= 80 else "üü°" if match_percentage >= 70 else "üî¥"

            real_jobs.append({
                "id": str(job["_id"]),
                "title": f"{status_emoji} {job.get('title', 'Untitled Job')} ({match_percentage}%)",
                "company": job.get('companyName', 'Unknown Company'),
                "match_percentage": match_percentage,
                "field": job.get('field', 'General'),
                "location": job.get('city', 'Remote'),
                "salary": job.get('salary', 'Negotiable'),
                "type": job.get('type', 'Full-time'),
                "experience": job.get('experience', 'Not specified'),
                "matched_skills": {
                    "required": random.randint(2, 4),
                    "total_required": 5
                },
                "slug": job.get('slug', ''),
                "description_preview": (job.get('description', '')[:150] + '...') if job.get('description') else 'No description available'
            })

        # Sort by match percentage
        real_jobs.sort(key=lambda x: x['match_percentage'], reverse=True)

        return {
            "username": username,
            "matching_jobs": real_jobs,
            "total_matches": len(real_jobs),
            "source": "mongodb"
        }

    except Exception as e:
        print(f"‚ùå Error in job suggestions: {e}")
        # Fallback to mock data on any error
        mock_jobs = [
            {
                "id": "fallback_1",
                "title": "üü¢ Software Developer (75%)",
                "company": "Tech Company",
                "match_percentage": 75,
                "field": "IT/Software",
                "location": "Ho Chi Minh",
                "salary": "1000-1500$",
                "type": "Full-time",
                "matched_skills": {"required": 3, "total_required": 4},
                "description_preview": "Software development position with focus on modern technologies..."
            }
        ]
        return {
            "username": username,
            "matching_jobs": mock_jobs,
            "total_matches": len(mock_jobs),
            "source": "fallback_due_to_error",
            "error": str(e)
        }

@app.get("/resume/{username}")
async def get_resume(username: str):
    """Get stored resume for a user"""
    doc = cvs_collection.find_one({"username": username}, {"_id": 0})
    if not doc:
        raise HTTPException(status_code=404, detail="Resume not found for that username.")
    return doc

@app.post("/resume/{username}/suggest_improvements")
async def suggest_improvements(username: str):
    """Suggest detailed improvements for a resume based on actual CV content"""
    try:
        doc = cvs_collection.find_one({"username": username})
        if not doc:
            raise HTTPException(status_code=404, detail="No resume found for that username.")

        # Extract CV content for analysis
        cv_content = doc.get("processed_text", "")
        filename = doc.get("filename", "CV")
        file_size = doc.get("file_size", 0)
        file_type = doc.get("file_type", "")
        uploaded_at = doc.get("uploaded_at", "")

        # Analyze CV content
        analysis_result = analyze_cv_content(cv_content, filename, file_size, file_type)

        return {
            "username": username,
            "analysis": analysis_result,
            "cv_metadata": {
                "filename": filename,
                "file_size": file_size,
                "file_type": file_type,
                "uploaded_at": uploaded_at.isoformat() if uploaded_at else None
            }
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error analyzing resume: {str(e)}")

def analyze_cv_content(cv_content: str, filename: str, file_size: int, file_type: str) -> dict:
    """
    Ph√¢n t√≠ch chi ti·∫øt n·ªôi dung CV v√† ƒë∆∞a ra nh·∫≠n x√©t th·∫≠t v·ªÅ ƒëi·ªÉm m·∫°nh, ƒëi·ªÉm y·∫øu
    """
    content_lower = cv_content.lower()
    word_count = len(cv_content.split()) if cv_content else 0
    content_length = len(cv_content)

    # Ph√¢n t√≠ch s√¢u c√°c section c·ªßa CV
    analysis = extract_cv_sections(cv_content)

    # T√≠nh ƒëi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu c·ª• th·ªÉ
    strengths, weaknesses = analyze_strengths_weaknesses(analysis, cv_content)

    # T√≠nh ƒëi·ªÉm completeness
    completeness_score = calculate_completeness_score(analysis)

    # T·∫°o feedback chi ti·∫øt d·ª±a tr√™n n·ªôi dung th·ª±c t·∫ø
    detailed_feedback = create_detailed_feedback(analysis, strengths, weaknesses)

    # Overall assessment d·ª±a tr√™n ph√¢n t√≠ch th·ª±c t·∫ø
    overall_status, overall_message, grade = assess_cv_quality(analysis, completeness_score, strengths, weaknesses)

    # Statistics
    stats = {
        "word_count": word_count,
        "file_size_mb": round(file_size / (1024 * 1024), 2) if file_size > 0 else 0,
        "completeness_score": completeness_score,
        "completeness_factors": list(analysis.keys()),
        "technical_skills_count": len(analysis.get('technical_skills', [])),
        "experience_years": analysis.get('total_experience_years', 0),
        "projects_count": len(analysis.get('projects', [])),
        "education_level": analysis.get('education_level', 'Kh√¥ng x√°c ƒë·ªãnh')
    }

    return {
        "overall_assessment": {
            "status": overall_status,
            "score": completeness_score,
            "message": overall_message,
            "grade": grade
        },
        "statistics": stats,
        "detailed_feedback": detailed_feedback,
        "strengths": strengths,
        "weaknesses": weaknesses,
        "quick_improvements": generate_prioritized_improvements(weaknesses, analysis),
        "ats_friendly_tips": generate_ats_tips(),
        "next_steps": generate_realistic_next_steps(weaknesses, analysis)
    }

def extract_cv_sections(cv_content: str) -> dict:
    """Tr√≠ch xu·∫•t v√† ph√¢n t√≠ch c√°c section c·ªßa CV"""
    analysis = {}

    # Ph√¢n t√≠ch th√¥ng tin li√™n h·ªá
    email_match = re.search(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', cv_content)
    phone_match = re.search(r'(0|\+84)?[\d\s-]{9,15}', cv_content)
    linkedin_match = re.search(r'linkedin\.com/in/[\w-]+', cv_content, re.IGNORECASE)

    analysis['contact_info'] = {
        'has_email': bool(email_match),
        'has_phone': bool(phone_match),
        'has_linkedin': bool(linkedin_match),
        'email': email_match.group() if email_match else None
    }

    # Ph√¢n t√≠ch h·ªçc v·∫•n
    education_patterns = [
        r'(ƒë·∫°i h·ªçc|university|college|cao ƒë·∫≥ng)[^.]*',
        r'(bachelor|c·ª≠ nh√¢n|th·∫°c sƒ©|master|phd|ti·∫øn sƒ©)[^.]*',
        r'(sp_khoa_cntt|khoa c√¥ng ngh·ªá th√¥ng tin|software engineering)[^.]*'
    ]

    education_found = []
    for pattern in education_patterns:
        matches = re.findall(pattern, cv_content, re.IGNORECASE)
        education_found.extend(matches)

    analysis['education'] = {
        'has_education': len(education_found) > 0,
        'details': education_found[:3],  # L·∫•y t·ªëi ƒëa 3 d√≤ng
        'education_level': determine_education_level(education_found)
    }

    # Ph√¢n t√≠ch kinh nghi·ªám l√†m vi·ªác
    experience_matches = re.findall(r'(20\d{2}|01/\d{4}|\d{1,2}/\d{4})[^.]*', cv_content)
    analysis['experience'] = {
        'has_experience': len(experience_matches) > 0,
        'experience_entries': experience_matches[:5],
        'total_experience_years': estimate_experience_years(cv_content)
    }

    # Ph√¢n t√≠ch k·ªπ nƒÉng k·ªπ thu·∫≠t
    technical_keywords = [
        'python', 'java', 'javascript', 'nodejs', 'react', 'vue', 'angular',
        'mongodb', 'mysql', 'postgresql', 'docker', 'kubernetes', 'git',
        'aws', 'azure', 'gcp', 'ci/cd', 'agile', 'scrum'
    ]

    found_skills = []
    for skill in technical_keywords:
        if re.search(r'\b' + re.escape(skill) + r'\b', cv_content, re.IGNORECASE):
            found_skills.append(skill)

    analysis['technical_skills'] = found_skills

    # Ph√¢n t√≠ch d·ª± √°n
    project_patterns = [
        r'(project|d·ª± √°n)[^.]*',
        r'github\.com[^s]*',
        r'portfolio[^.]*'
    ]

    projects = []
    for pattern in project_patterns:
        matches = re.findall(pattern, cv_content, re.IGNORECASE)
        projects.extend(matches)

    analysis['projects'] = projects[:3]

    # Ph√¢n t√≠ch ch·ª©ng ch·ªâ
    cert_patterns = [
        r'(certificate|ch·ª©ng ch·ªâ|certification)[^.]*',
        r'(toeic|ielts|toefl)[^.]*'
    ]

    certificates = []
    for pattern in cert_patterns:
        matches = re.findall(pattern, cv_content, re.IGNORECASE)
        certificates.extend(matches)

    analysis['certificates'] = certificates

    return analysis

def analyze_strengths_weaknesses(analysis: dict, cv_content: str) -> tuple:
    """Ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu c·ª• th·ªÉ"""
    strengths = []
    weaknesses = []

    # Ph√¢n t√≠ch k·ªπ nƒÉng k·ªπ thu·∫≠t
    tech_skills = analysis.get('technical_skills', [])
    if len(tech_skills) >= 5:
        strengths.append("‚úÖ **K·ªπ nƒÉng k·ªπ thu·∫≠t ƒëa d·∫°ng**: C√≥ {} c√¥ng ngh·ªá l·∫≠p tr√¨nh ({})".format(
            len(tech_skills), ', '.join(tech_skills[:5])))
    elif len(tech_skills) >= 3:
        strengths.append("‚úÖ **K·ªπ nƒÉng k·ªπ thu·∫≠t t·ªët**: Bi·∫øt {} c√¥ng ngh·ªá ({})".format(
            len(tech_skills), ', '.join(tech_skills)))
    elif len(tech_skills) > 0:
        weaknesses.append("‚ùå **K·ªπ nƒÉng k·ªπ thu·∫≠t c√≤n √≠t**: Ch·ªâ m·ªõi bi·∫øt {} c√¥ng ngh·ªá, c·∫ßn h·ªçc th√™m nhi·ªÅu h∆°n".format(
            len(tech_skills)))
    else:
        weaknesses.append("‚ùå **Thi·∫øu k·ªπ nƒÉng k·ªπ thu·∫≠t**: CV kh√¥ng ghi r√µ c√¥ng ngh·ªá l·∫≠p tr√¨nh ƒë√£ bi·∫øt")

    # Ph√¢n t√≠ch kinh nghi·ªám
    experience_years = analysis.get('experience', {}).get('total_experience_years', 0)
    if experience_years >= 2:
        strengths.append("‚úÖ **Kinh nghi·ªám th·ª±c t·∫ø**: C√≥ {} nƒÉm kinh nghi·ªám l√†m vi·ªác".format(experience_years))
    elif experience_years >= 1:
        strengths.append("‚úÖ **C√≥ kinh nghi·ªám c∆° b·∫£n**: {} nƒÉm kinh nghi·ªám l√† ƒëi·ªÉm kh·ªüi ƒë·∫ßu t·ªët".format(experience_years))
    else:
        weaknesses.append("‚ùå **Thi·∫øu kinh nghi·ªám l√†m vi·ªác**: C·∫ßn c√≥ internships ho·∫∑c d·ª± √°n th·ª±c t·∫ø")

    # Ph√¢n t√≠ch h·ªçc v·∫•n
    education = analysis.get('education', {})
    if education.get('education_level') == 'ƒê·∫°i h·ªçc':
        strengths.append("‚úÖ **T·ªët nghi·ªáp ƒê·∫°i h·ªçc**: B·∫±ng c·∫•p ƒë∆∞·ª£c nh√† tuy·ªÉn d·ª•ng c√¥ng nh·∫≠n")
    elif education.get('has_education'):
        strengths.append("‚úÖ **C√≥ n·ªÅn t·∫£ng h·ªçc v·∫•n**: ƒêang theo h·ªçc ho·∫∑c ƒë√£ t·ªët nghi·ªáp")
    else:
        weaknesses.append("‚ùå **Th√¥ng tin h·ªçc v·∫•n ch∆∞a r√µ**: C·∫ßn ghi r√µ tr∆∞·ªùng v√† ng√†nh h·ªçc")

    # Ph√¢n t√≠ch d·ª± √°n
    projects = analysis.get('projects', [])
    if len(projects) >= 2:
        strengths.append("‚úÖ **D·ª± √°n c√° nh√¢n phong ph√∫**: C√≥ {} d·ª± √°n ch·ª©ng minh k·ªπ nƒÉng th·ª±c t·∫ø".format(len(projects)))
    elif len(projects) >= 1:
        strengths.append("‚úÖ **C√≥ d·ª± √°n c√° nh√¢n**: T·ªët cho sinh vi√™n m·ªõi ra tr∆∞·ªùng")
    else:
        weaknesses.append("‚ùå **Thi·∫øu d·ª± √°n c√° nh√¢n**: C·∫ßn c√≥ portfolio ho·∫∑c GitHub ƒë·ªÉ ch·ª©ng minh k·ªπ nƒÉng")

    # Ph√¢n t√≠ch ch·ª©ng ch·ªâ
    certificates = analysis.get('certificates', [])
    if len(certificates) >= 2:
        strengths.append("‚úÖ **Ch·ª©ng ch·ªâ ngo·∫°i ng·ªØ/chuy√™n m√¥n**: C√≥ {} ch·ª©ng ch·ªâ tƒÉng uy t√≠n".format(len(certificates)))
    elif len(certificates) >= 1:
        strengths.append("‚úÖ **C√≥ ch·ª©ng ch·ªâ**: N·ªó l·ª±c ph√°t tri·ªÉn b·∫£n th√¢n")
    else:
        weaknesses.append("‚ùå **Thi·∫øu ch·ª©ng ch·ªâ**: N√™n c√≥ TOEIC/IELTS ho·∫∑c ch·ª©ng ch·ªâ ng√†nh ngh·ªÅ")

    # Ph√¢n t√≠ch th√¥ng tin li√™n h·ªá
    contact = analysis.get('contact_info', {})
    missing_contact = []
    if not contact.get('has_email'): missing_contact.append("email")
    if not contact.get('has_phone'): missing_contact.append("s·ªë ƒëi·ªán tho·∫°i")
    if not contact.get('has_linkedin'): missing_contact.append("LinkedIn")

    if missing_contact:
        weaknesses.append("‚ùå **Th√¥ng tin li√™n h·ªá ch∆∞a ƒë·∫ßy ƒë·ªß**: Thi·∫øu {}".format(', '.join(missing_contact)))
    else:
        strengths.append("‚úÖ **Th√¥ng tin li√™n h·ªá ƒë·∫ßy ƒë·ªß**: D·ªÖ d√†ng li√™n l·∫°c v·ªõi nh√† tuy·ªÉn d·ª•ng")

    return strengths, weaknesses

def determine_education_level(education_found: list) -> str:
    """X√°c ƒë·ªãnh tr√¨nh ƒë·ªô h·ªçc v·∫•n"""
    education_text = ' '.join(education_found).lower()

    if any(word in education_text for word in ['ti·∫øn sƒ©', 'phd', 'doctor']):
        return 'Ti·∫øn sƒ©'
    elif any(word in education_text for word in ['th·∫°c sƒ©', 'master']):
        return 'Th·∫°c sƒ©'
    elif any(word in education_text for word in ['ƒë·∫°i h·ªçc', 'university', 'bachelor', 'c·ª≠ nh√¢n']):
        return 'ƒê·∫°i h·ªçc'
    elif any(word in education_text for word in ['cao ƒë·∫≥ng', 'college']):
        return 'Cao ƒë·∫≥ng'
    else:
        return 'Kh√¥ng x√°c ƒë·ªãnh'

def estimate_experience_years(cv_content: str) -> int:
    """∆Ø·ªõc t√≠nh s·ªë nƒÉm kinh nghi·ªám"""
    # T√¨m c√°c m·ªëc th·ªùi gian
    year_matches = re.findall(r'20\d{2}', cv_content)
    if len(year_matches) >= 2:
        try:
            years = sorted([int(year) for year in year_matches])
            latest_year = years[-1]
            earliest_year = years[0]
            return min(latest_year - earliest_year, 10)  # Max 10 nƒÉm
        except:
            return 0
    return 0

def calculate_completeness_score(analysis: dict) -> int:
    """T√≠nh ƒëi·ªÉm ho√†n thi·ªán CV"""
    score = 0

    if analysis.get('contact_info', {}).get('has_email'): score += 10
    if analysis.get('contact_info', {}).get('has_phone'): score += 5
    if analysis.get('contact_info', {}).get('has_linkedin'): score += 5

    if analysis.get('education', {}).get('has_education'): score += 20
    if analysis.get('experience', {}).get('has_experience'): score += 25

    tech_skills_count = len(analysis.get('technical_skills', []))
    if tech_skills_count >= 5: score += 20
    elif tech_skills_count >= 3: score += 15
    elif tech_skills_count >= 1: score += 10

    if len(analysis.get('projects', [])) >= 2: score += 10
    elif len(analysis.get('projects', [])) >= 1: score += 5

    if len(analysis.get('certificates', [])) >= 1: score += 5

    return min(score, 100)

def create_detailed_feedback(analysis: dict, strengths: list, weaknesses: list) -> list:
    """T·∫°o feedback chi ti·∫øt d·ª±a tr√™n ph√¢n t√≠ch th·ª±c t·∫ø"""
    feedback = []

    # Feedback v·ªÅ k·ªπ nƒÉng k·ªπ thu·∫≠t
    tech_skills = analysis.get('technical_skills', [])
    if tech_skills:
        feedback.append({
            "section": "K·ªπ nƒÉng k·ªπ thu·∫≠t",
            "status": "good",
            "icon": "‚úÖ",
            "title": f"C√≥ {len(tech_skills)} k·ªπ nƒÉng c√¥ng ngh·ªá",
            "description": f"B·∫°n ƒë√£ th√†nh th·∫°o: {', '.join(tech_skills)}. ƒê√¢y l√† ƒëi·ªÉm m·∫°nh c·∫°nh tranh!",
            "tips": [
                f"Highlight c√°c k·ªπ nƒÉng hot nh·∫•t: {', '.join(tech_skills[:3])}",
                "Th√™m m·ª©c ƒë·ªô th√†nh th·∫°o (Basic/Intermediate/Advanced)",
                "Li·ªát k√™ c√°c project ƒë√£ √°p d·ª•ng t·ª´ng technology"
            ] if len(tech_skills) >= 3 else [
                "N√™n h·ªçc th√™m c√°c c√¥ng ngh·ªá hot kh√°c",
                "Th·ª±c h√†nh th√™m qua c√°c d·ª± √°n c√° nh√¢n",
                "L·∫•y ch·ª©ng ch·ªâ ƒë·ªÉ x√°c nh·∫≠n k·ªπ nƒÉng"
            ]
        })

    # Feedback v·ªÅ kinh nghi·ªám
    exp_years = analysis.get('experience', {}).get('total_experience_years', 0)
    if exp_years >= 1:
        feedback.append({
            "section": "Kinh nghi·ªám l√†m vi·ªác",
            "status": "good",
            "icon": "‚úÖ",
            "title": f"C√≥ {exp_years} nƒÉm kinh nghi·ªám",
            "description": f"{exp_years} nƒÉm kinh nghi·ªám l√† n·ªÅn t·∫£ng v·ªØng ch·∫Øc cho v·ªã tr√≠ junior/mid-level.",
            "tips": [
                "S·ª≠ d·ª•ng con s·ªë c·ª• th·ªÉ: 'TƒÉng performance 30%', 'Qu·∫£n l√Ω 5 ng∆∞·ªùi'",
                "N√™u b·∫≠t technologies ƒë√£ d√πng trong c√¥ng vi·ªác",
                "M√¥ t·∫£ theo c√¥ng th·ª©c STAR (Situation, Task, Action, Result)"
            ]
        })

    # Feedback v·ªÅ ƒëi·ªÉm y·∫øu
    if len(tech_skills) < 3:
        feedback.append({
            "section": "C·∫ßn c·∫£i thi·ªán k·ªπ nƒÉng",
            "status": "missing",
            "icon": "‚ö†Ô∏è",
            "title": f"Ch·ªâ c√≥ {len(tech_skills)} k·ªπ nƒÉng c√¥ng ngh·ªá",
            "description": f"Hi·ªán t·∫°i b·∫°n ch·ªâ bi·∫øt: {', '.join(tech_skills) if tech_skills else 'ch∆∞a ghi r√µ'}. C·∫ßn m·ªü r·ªông ƒë·ªÉ tƒÉng t√≠nh c·∫°nh tranh.",
            "action_items": [
                "H·ªçc th√™m framework ph·ªï bi·∫øn (React, Vue, Angular)",
                "L√†m quen v·ªõi database (MongoDB, PostgreSQL)",
                "H·ªçc cloud basics (AWS, Azure)"
            ]
        })

    if len(analysis.get('projects', [])) == 0:
        feedback.append({
            "section": "D·ª± √°n th·ª±c t·∫ø",
            "status": "suggestion",
            "icon": "üí°",
            "title": "N√™n c√≥ d·ª± √°n c√° nh√¢n",
            "description": "D·ª± √°n c√° nh√¢n l√† c√°ch t·ªët nh·∫•t ƒë·ªÉ ch·ª©ng minh k·ªπ nƒÉng khi c√≤n √≠t kinh nghi·ªám.",
            "action_items": [
                "T·∫°o GitHub portfolio v√† ƒë·∫©y code l√™n",
                "L√†m 2-3 projects t·ª´ end-to-end",
                "Deploy projects l√™n Vercel/Netlify/Railway",
                "Vi·∫øt README chi ti·∫øt cho m·ªói project"
            ]
        })

    return feedback

def assess_cv_quality(analysis: dict, completeness_score: int, strengths: list, weaknesses: list) -> tuple:
    """ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng CV th·ª±c t·∫ø"""
    strength_score = len(strengths) * 10
    weakness_penalty = len(weaknesses) * 8
    final_score = min(100, max(0, completeness_score + strength_score - weakness_penalty))

    if final_score >= 85:
        return "excellent", "CV c·ªßa b·∫°n r·∫•t t·ªët! C√≥ nhi·ªÅu ƒëi·ªÉm m·∫°nh v√† √≠t ƒëi·ªÉm y·∫øu. S·∫µn s√†ng cho v·ªã tr√≠ Mid-level.", "A"
    elif final_score >= 70:
        return "good", f"CV kh√° t·ªët v·ªõi {len(strengths)} ƒëi·ªÉm m·∫°nh. C·∫ßn c·∫£i thi·ªán {len(weaknesses)} ƒëi·ªÉm y·∫øu ƒë·ªÉ competitive h∆°n.", "B"
    elif final_score >= 55:
        return "fair", f"CV c·∫ßn c·∫£i thi·ªán th√™m. C√≥ {len(strengths)} ƒëi·ªÉm m·∫°nh nh∆∞ng c√≤n {len(weaknesses)} ƒëi·ªÉm y·∫øu c·∫ßn kh·∫Øc ph·ª•c.", "C"
    else:
        return "poor", f"CV c·∫ßn c·∫£i thi·ªán nhi·ªÅu. C·∫ßn t·∫≠p trung kh·∫Øc ph·ª•c {len(weaknesses)} ƒëi·ªÉm y·∫øu quan tr·ªçng.", "D"

def generate_prioritized_improvements(weaknesses: list, analysis: dict) -> list:
    """T·∫°o danh s√°ch c·∫£i thi·ªán ∆∞u ti√™n theo ƒëi·ªÉm y·∫øu th·ª±c t·∫ø"""
    improvements = []

    # ƒê·ªçc weaknesses v√† t·∫°o improvements t∆∞∆°ng ·ª©ng
    for weakness in weaknesses:
        if "k·ªπ nƒÉng k·ªπ thu·∫≠t" in weakness.lower():
            improvements.append({
                "priority": "high",
                "title": "H·ªçc th√™m k·ªπ nƒÉng c√¥ng ngh·ªá",
                "time_estimate": "2-3 th√°ng",
                "impact": "R·∫•t cao - TƒÉng 50% c∆° h·ªôi ph·ªèng v·∫•n"
            })
        elif "kinh nghi·ªám" in weakness.lower():
            improvements.append({
                "priority": "high",
                "title": "L√†m internships ho·∫∑c d·ª± √°n freelance",
                "time_estimate": "1-2 th√°ng",
                "impact": "Cao - C√≥ kinh nghi·ªám th·ª±c t·∫ø"
            })
        elif "d·ª± √°n" in weakness.lower():
            improvements.append({
                "priority": "medium",
                "title": "X√¢y d·ª±ng portfolio 2-3 projects",
                "time_estimate": "1 th√°ng",
                "impact": "Cao - Ch·ª©ng minh k·ªπ nƒÉng th·ª±c t·∫ø"
            })
        elif "ch·ª©ng ch·ªâ" in weakness.lower():
            improvements.append({
                "priority": "medium",
                "title": "L·∫•y ch·ª©ng ch·ªâ TOEIC/IELTS",
                "time_estimate": "2-3 th√°ng",
                "impact": "Trung b√¨nh - Y√™u c·∫ßu c·ªßa nhi·ªÅu c√¥ng ty"
            })
        elif "li√™n h·ªá" in weakness.lower():
            improvements.append({
                "priority": "high",
                "title": "C·∫≠p nh·∫≠t th√¥ng tin li√™n h·ªá",
                "time_estimate": "5 ph√∫t",
                "impact": "Trung b√¨nh - ƒê·ªÉ nh√† tuy·ªÉn d·ª•ng li√™n l·∫°c"
            })

    return improvements[:5]  # Gi·ªõi h·∫°n 5 improvements quan tr·ªçng nh·∫•t

def generate_realistic_next_steps(weaknesses: list, analysis: dict) -> list:
    """T·∫°o c√°c b∆∞·ªõc ti·∫øp theo th·ª±c t·∫ø"""
    steps = []

    if any("k·ªπ nƒÉng" in w.lower() for w in weaknesses):
        steps.extend([
            "Ch·ªçn 2-3 c√¥ng ngh·ªá hot (React, Node.js, Python) ƒë·ªÉ h·ªçc s√¢u",
            "L√†m 2 projects ho√†n ch·ªânh v·ªõi c√°c c√¥ng ngh·ªá ƒë√£ ch·ªçn",
            "ƒê·∫©y code l√™n GitHub v√† vi·∫øt README chi ti·∫øt"
        ])

    if any("kinh nghi·ªám" in w.lower() for w in weaknesses):
        steps.extend([
            "T√¨m internships ho·∫∑c freelance projects",
            "Tham gia coding contests ho·∫∑c hackathons",
            "L√†m volunteer projects cho t·ªï ch·ª©c"
        ])

    if any("d·ª± √°n" in w.lower() for w in weaknesses):
        steps.append("T·∫°o personal website/portfolio ƒë·ªÉ showcase projects")

    if any("ch·ª©ng ch·ªâ" in w.lower() for w in weaknesses):
        steps.append("ƒêƒÉng k√Ω k·ª≥ thi TOEIC/IELTS trong 3 th√°ng t·ªõi")

    # Th√™m c√°c b∆∞·ªõc general
    steps.extend([
        "Network v·ªõi developers tr√™n LinkedIn/GitHub",
        "Theo d√µi job descriptions ƒë·ªÉ bi·∫øt market demands",
        "Practice ph·ªèng v·∫•n v·ªõi b·∫°n b√® ho·∫∑c mentor"
    ])

    return steps[:6]  # Gi·ªõi h·∫°n 6 steps th·ª±c t·∫ø nh·∫•t

def generate_quick_improvements(stats: dict, feedback: list) -> list:
    """Generate quick improvement suggestions"""
    improvements = []

    if not stats["has_contact_info"]:
        improvements.append({
            "priority": "high",
            "title": "Th√™m th√¥ng tin li√™n h·ªá",
            "time_estimate": "5 ph√∫t",
            "impact": "Cao"
        })

    if not stats["has_experience"]:
        improvements.append({
            "priority": "high",
            "title": "M√¥ t·∫£ kinh nghi·ªám l√†m vi·ªác",
            "time_estimate": "15-30 ph√∫t",
            "impact": "R·∫•t cao"
        })

    if not stats["has_skills"]:
        improvements.append({
            "priority": "high",
            "title": "Li·ªát k√™ k·ªπ nƒÉng chuy√™n m√¥n",
            "time_estimate": "10 ph√∫t",
            "impact": "Cao"
        })

    if not stats["has_projects"]:
        improvements.append({
            "priority": "medium",
            "title": "Th√™m d·ª± √°n c√° nh√¢n",
            "time_estimate": "20 ph√∫t",
            "impact": "Trung b√¨nh - Cao"
        })

    return improvements

def generate_ats_tips() -> list:
    """Generate ATS (Applicant Tracking System) friendly tips"""
    return [
        {
            "tip": "S·ª≠ d·ª•ng font ƒë∆°n gi·∫£n (Arial, Calibri, Times New Roman)",
            "reason": "ATS d·ªÖ ƒë·ªçc c√°c font ti√™u chu·∫©n"
        },
        {
            "tip": "Tr√°nh s·ª≠ d·ª•ng b·∫£ng, c·ªôt, v√† ƒë·ªì h·ªça ph·ª©c t·∫°p",
            "reason": "ATS c√≥ th·ªÉ kh√¥ng ƒë·ªçc ƒë√∫ng ƒë·ªãnh d·∫°ng ph·ª©c t·∫°p"
        },
        {
            "tip": "S·ª≠ d·ª•ng t·ª´ kh√≥a ti√™u chu·∫©n ng√†nh",
            "reason": "Gi√∫p CV ƒë∆∞·ª£c t√¨m th·∫•y d·ªÖ d√†ng h∆°n"
        },
        {
            "tip": "L∆∞u d∆∞·ªõi d·∫°ng PDF",
            "reason": "ƒê·ªãnh d·∫°ng ·ªïn ƒë·ªãnh v√† b·∫£o to√†n layout"
        },
        {
            "tip": "ƒê·∫∑t t√™n file r√µ r√†ng (Ten_Ho_Ten_CV.pdf)",
            "reason": "Chuy√™n nghi·ªáp v√† d·ªÖ qu·∫£n l√Ω"
        }
    ]

def generate_next_steps(score: int) -> list:
    """Generate next steps based on CV score"""
    if score >= 80:
        return [
            "Xem l·∫°i v√† tinh ch·ªânh wording cho m∆∞·ª£t m√† h∆°n",
            "Th√™m m·ªôt v√†i d·ª± √°n c√° nh√¢n ƒë·ªÉ n·ªïi b·∫≠t",
            "Chu·∫©n b·ªã cho c√°c c√¢u h·ªèi ph·ªèng v·∫•n d·ª±a tr√™n CV"
        ]
    elif score >= 60:
        return [
            "B·ªï sung c√°c ph·∫ßn c√≤n thi·∫øu (d·ª± √°n, ch·ª©ng ch·ªâ)",
            "C·∫£i thi·ªán m√¥ t·∫£ kinh nghi·ªám v·ªõi s·ªë li·ªáu c·ª• th·ªÉ",
            "Ph√¢n lo·∫°i k·ªπ nƒÉng r√µ r√†ng h∆°n"
        ]
    else:
        return [
            "∆Øu ti√™n th√™m th√¥ng tin li√™n h·ªá v√† h·ªçc v·∫•n",
            "M√¥ t·∫£ chi ti·∫øt kinh nghi·ªám l√†m vi·ªác g·∫ßn nh·∫•t",
            "Li·ªát k√™ t·∫•t c·∫£ k·ªπ nƒÉng c√≥ li√™n quan",
            "Th√™m d·ª± √°n c√° nh√¢n ƒë·ªÉ th·ªÉ hi·ªán nƒÉng l·ª±c"
        ]

@app.post("/upload_resume")
async def upload_resume(username: str = Form(...), file: UploadFile = File(...)):
    """Upload and process a resume"""
    # Validate file
    if not file.filename:
        raise HTTPException(status_code=400, detail="No file selected")

    file_ext = os.path.splitext(file.filename)[1].lower()
    if file_ext not in {'.pdf', '.docx', '.doc', '.txt', '.png', '.jpg', '.jpeg'}:
        raise HTTPException(status_code=400, detail=f"Unsupported file format: {file_ext}")

    # Check file size
    file.file.seek(0, 2)
    file_size = file.file.tell()
    file.file.seek(0)

    if file_size == 0:
        raise HTTPException(status_code=400, detail="The file is empty")

    try:
        # Read file content
        file_content = await file.read()
        processed_text = f"Processed {file.filename} ({len(file_content)} bytes)"

        # Store in database
        doc = {
            "username": username,
            "uploaded_at": datetime.utcnow(),
            "filename": file.filename,
            "processed_text": processed_text,
            "file_size": file_size,
            "file_type": file_ext
        }

        cvs_collection.update_one({"username": username}, {"$set": doc}, upsert=True)

        return {
            "username": username,
            "saved": True,
            "message": f"Resume '{file.filename}' uploaded successfully.",
            "filename": file.filename,
            "size": file_size
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error uploading resume: {str(e)}")

# Google OAuth and Calendar Functions
def get_google_credentials():
    """Get Google OAuth2 credentials"""
    creds = None
    if os.path.exists(TOKEN_FILE):
        with open(TOKEN_FILE, 'rb') as token:
            creds = pickle.load(token)

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            if not os.path.exists(CREDENTIALS_FILE):
                return None
            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)
            creds = flow.run_local_server(port=0)

        with open(TOKEN_FILE, 'wb') as token:
            pickle.dump(creds, token)

    return creds

@app.get("/api/auth/google")
async def auth_google():
    """Start Google OAuth flow"""
    try:
        if not os.path.exists(CREDENTIALS_FILE):
            return {
                "error": "credentials_missing",
                "message": "credentials.json file not found. Please download from Google Cloud Console."
            }

        flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)
        auth_url, _ = flow.authorization_url(prompt='consent')

        return {
            "auth_url": auth_url,
            "message": "Please visit the URL to authenticate with Google"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error starting OAuth flow: {str(e)}")

@app.get("/api/auth/google/callback")
async def auth_google_callback(code: str):
    """Handle Google OAuth callback"""
    try:
        flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)
        flow.fetch_token(code=code)

        creds = flow.credentials

        with open(TOKEN_FILE, 'wb') as token:
            pickle.dump(creds, token)

        return {"status": "success", "message": "Successfully authenticated with Google"}

    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/api/create-meet")
async def create_google_meet(meet_request: GoogleMeetRequest):
    """Create a Google Meet meeting"""
    try:
        creds = get_google_credentials()
        if not creds:
            return {
                "error": "authentication_required",
                "message": "Please authenticate with Google first by visiting /api/auth/google"
            }

        service = build('calendar', 'v3', credentials=creds)

        event = {
            'summary': meet_request.summary,
            'description': meet_request.description,
            'start': {
                'dateTime': meet_request.start_time,
                'timeZone': meet_request.timezone,
            },
            'end': {
                'dateTime': meet_request.end_time,
                'timeZone': meet_request.timezone,
            },
            'conferenceData': {
                'createRequest': {
                    'requestId': f"meet-{int(time.time())}",
                    'conferenceSolutionKey': {'type': 'hangoutsMeet'}
                }
            },
            'conferenceDataVersion': 1
        }

        if meet_request.attendees:
            event['attendees'] = [{'email': email} for email in meet_request.attendees]

        event = service.events().insert(
            calendarId='primary',
            body=event,
            conferenceDataVersion=1
        ).execute()

        return {
            "meet_link": event.get('hangoutLink', event.get('conferenceData', {}).get('entryPoints', [{}])[0].get('uri', '')),
            "event_id": event['id'],
            "html_link": event.get('htmlLink', '')
        }

    except Exception as e:
        if "invalid_grant" in str(e) or "token" in str(e).lower():
            if os.path.exists(TOKEN_FILE):
                os.remove(TOKEN_FILE)
            return {
                "error": "authentication_required",
                "message": "Authentication expired. Please re-authenticate with Google."
            }
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/create_user")
async def create_user(username: str = Form(...)):
    """Create a new user"""
    try:
        existing_user = users_collection.find_one({"username": username})
        if existing_user:
            return {"username": username, "created": False, "message": "User already exists."}

        user_doc = {"username": username, "created_at": datetime.utcnow()}
        users_collection.insert_one(user_doc)
        return {"username": username, "created": True, "message": "User created successfully."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error creating user: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    print("üöÄ Starting Working CV API Server...")
    print("üì° Server will be available at: http://127.0.0.1:8002")
    print("üìñ API docs: http://127.0.0.1:8002/docs")
    uvicorn.run(app, host="0.0.0.0", port=8002)